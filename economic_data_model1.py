# -*- coding: utf-8 -*-
"""Economic Data Model1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xoeK0x7kpSw8jJ9PBWTwOHBAKH9Va1uc
"""

import requests
import pandas as pd
from fredapi import Fred

fred = Fred(api_key = 'fd0c3925530e1adec9762968a731218b')
api_key = ('fd0c3925530e1adec9762968a731218b')
start_date = '1970-01-01'
end_date = '2025-06-30'

"""# Inflation Data"""

# Inflation - Consumer Price Index (CPI)
series_id_cpi = 'CPIAUCSL'
units_cpi = 'pch'        # Percent change (Month-over-Month %)
frequency_cpi = 'm'      # Monthly

# URL and parameters
url_cpi = "https://api.stlouisfed.org/fred/series/observations"
params_cpi = {
    'series_id': series_id_cpi,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_cpi,
    'frequency': frequency_cpi,
    'observation_start': start_date,
    'observation_end': end_date,
}

# Make the request
response_cpi = requests.get(url_cpi, params=params_cpi)

# Format response
if response_cpi.status_code == 200:
    data_cpi = response_cpi.json()
    df_cpi = pd.DataFrame(data_cpi['observations'])

    df_cpi['date'] = pd.to_datetime(df_cpi['date'])
    df_cpi['value'] = pd.to_numeric(df_cpi['value'], errors='coerce')
    df_cpi = df_cpi[['date', 'value']].set_index('date')
    df_cpi = df_cpi.dropna()

    df_cpi.rename(columns={'value': 'CPI MoM %'}, inplace=True)
    df_cpi.index.name = "Date"

    print(df_cpi.head(10))

else:
    print('Failed to retrieve CPI data.')
    print('Status Code:', response_cpi.status_code)
    print(response_cpi.text)

# Core CPI - Core Consumer Price Index (YoY % or desired units)
series_id_core_cpi = 'CPILFESL'
units_core_cpi = 'pch'        # Percent change from previous period (you can adjust to 'pc1' for YoY if needed)
frequency_core_cpi = 'm'      # Monthly
start_date_core_cpi = '1970-01-01'
end_date_core_cpi = '2025-06-30'

# URL and parameters
url_core_cpi = "https://api.stlouisfed.org/fred/series/observations"
params_core_cpi = {
    'series_id': series_id_core_cpi,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_core_cpi,
    'frequency': frequency_core_cpi,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_core_cpi = requests.get(url_core_cpi, params=params_core_cpi)

# Format response
if response_core_cpi.status_code == 200:
    data_core_cpi = response_core_cpi.json()
    df_core_cpi = pd.DataFrame(data_core_cpi['observations'])

    df_core_cpi['date'] = pd.to_datetime(df_core_cpi['date'])
    df_core_cpi['value'] = pd.to_numeric(df_core_cpi['value'], errors='coerce')
    df_core_cpi = df_core_cpi[['date', 'value']].set_index('date')
    df_core_cpi = df_core_cpi.dropna()

    df_core_cpi.rename(columns={'value': 'Core CPI (MoM %)'}, inplace=True)
    df_core_cpi.index.name = "Date"

    print(df_core_cpi.head(10))

else:
    print('Failed to retrieve Core CPI data.')
    print('Status Code:', response_core_cpi.status_code)
    print(response_core_cpi.text)

# Cost Pressures - Producer Price Index (All Commodities)
series_id_ppi = 'PPIACO'
units_ppi = 'pch'        # Percent change (month-over-month)
frequency_ppi = 'm'      # Monthly
start_date_ppi = '1970-01-01'
end_date_ppi = '2025-06-30'

# URL and parameters
url_ppi = "https://api.stlouisfed.org/fred/series/observations"
params_ppi = {
    'series_id': series_id_ppi,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_ppi,
    'frequency': frequency_ppi,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_ppi = requests.get(url_ppi, params=params_ppi)

# Format response
if response_ppi.status_code == 200:
    data_ppi = response_ppi.json()
    df_ppi = pd.DataFrame(data_ppi['observations'])

    df_ppi['date'] = pd.to_datetime(df_ppi['date'])
    df_ppi['value'] = pd.to_numeric(df_ppi['value'], errors='coerce')
    df_ppi = df_ppi[['date', 'value']].set_index('date')
    df_ppi = df_ppi.dropna()

    df_ppi.rename(columns={'value': 'PPI (MoM %)'}, inplace=True)
    df_ppi.index.name = "Date"

    print(df_ppi.head(10))

else:
    print('Failed to retrieve PPI data.')
    print('Status Code:', response_ppi.status_code)
    print(response_ppi.text)

# Inflation Expectations - 5-Year Breakeven Inflation Rate
series_id_t5yie = 'T5YIE'
units_t5yie = 'lin'        # No transformation (raw levels)
frequency_t5yie = 'm'      # Monthly
start_date_t5yie = '1970-01-01'
end_date_t5yie = '2025-06-30'

# URL and parameters
url_t5yie = "https://api.stlouisfed.org/fred/series/observations"
params_t5yie = {
    'series_id': series_id_t5yie,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_t5yie,
    'frequency': frequency_t5yie,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_t5yie = requests.get(url_t5yie, params=params_t5yie)

# Format response
if response_t5yie.status_code == 200:
    data_t5yie = response_t5yie.json()
    df_t5yie = pd.DataFrame(data_t5yie['observations'])

    df_t5yie['date'] = pd.to_datetime(df_t5yie['date'])
    df_t5yie['value'] = pd.to_numeric(df_t5yie['value'], errors='coerce')
    df_t5yie = df_t5yie[['date', 'value']].set_index('date')
    df_t5yie = df_t5yie.dropna()

    df_t5yie.rename(columns={'value': '5Y Breakeven Inflation Rate'}, inplace=True)
    df_t5yie.index.name = "Date"

    print(df_t5yie.head(10))

else:
    print('Failed to retrieve T5YIE data.')
    print('Status Code:', response_t5yie.status_code)
    print(response_t5yie.text)

# Consumer Sentiment - University of Michigan (Index)
series_id_MICH = 'MICH'
units_MICH = 'lin'        # No transformation
frequency_MICH = 'm'      # Monthly
start_date_MICH = '1985-01-01'
end_date_MICH = '2025-06-30'

# URL and parameters
url_MICH = "https://api.stlouisfed.org/fred/series/observations"
params_MICH = {
    'series_id': series_id_MICH,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_MICH,
    'frequency': frequency_MICH,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_MICH = requests.get(url_MICH, params=params_MICH)

# Format response
if response_MICH.status_code == 200:
    data_MICH = response_MICH.json()
    df_MICH = pd.DataFrame(data_MICH['observations'])

    df_MICH['date'] = pd.to_datetime(df_MICH['date'])
    df_MICH['value'] = pd.to_numeric(df_MICH['value'], errors='coerce')
    df_MICH = df_MICH[['date', 'value']].set_index('date')
    df_MICH = df_MICH.dropna()

    df_MICH.rename(columns={'value': 'Consumer Sentiment Index (UMich)'}, inplace=True)
    df_MICH.index.name = "Date"

    print(df_MICH.head(10))

else:
    print('Failed to retrieve MICH data.')
    print('Status Code:', response_MICH.status_code)
    print(response_MICH.text)

# ---- STEP 1: Concatenate all Growth Theme indicators ----
df_inflation_data = pd.concat([
    df_MICH,
    df_core_cpi,
    df_cpi,
    df_ppi,
    df_t5yie
], axis=1)

# ---- STEP 2: Drop rows with missing values (e.g., incomplete early dates) ----
first_valid_date = df_inflation_data.dropna().index.min()
df_inflation_data = df_inflation_data.loc[first_valid_date:]

# ---- STEP 3: Forward-fill quarterly values like GDP if needed ----
df_inflation_data = df_inflation_data.ffill()

# ---- STEP 4: Round only numeric columns safely ----
numeric_cols = df_inflation_data.select_dtypes(include=['float64', 'int64']).columns
for col in numeric_cols:
    df_inflation_data[col] = df_inflation_data[col].round(2)

# ---- STEP 5: Reset index and name it 'Date' for clean presentation ----
df_inflation_data = df_inflation_data.reset_index()
df_inflation_data.rename(columns={'index': 'Date'}, inplace=True)

# ---- STEP 6: Preview final cleaned dataset ----

print(df_inflation_data.head())

df_inflation_data.to_csv("inflation_data.csv", index = False)





"""# Growth Data"""

# Production- Industrial Production
series_id_ind_prod = 'INDPRO'
units_ind_prod = 'pch'        # No transformation #raw difference in yield (%) between the 10-year and 2-year U.S. Treasury bonds
frequency_ind_prod = 'm'      # Monthly
start_date_ind_prod = '1970-01-01'
end_date_ind_prod = '2025-04-23'

# URL and parameters
url_ind_prod = "https://api.stlouisfed.org/fred/series/observations"
params_ind_prod = {
    'series_id': series_id_ind_prod,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_ind_prod,
    'frequency': frequency_ind_prod,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_ind_prod = requests.get(url_ind_prod, params=params_ind_prod)

# Format response
if response_ind_prod.status_code == 200:
    data_ind_prod = response_ind_prod.json()
    df_ind_prod = pd.DataFrame(data_ind_prod['observations'])

    df_ind_prod['date'] = pd.to_datetime(df_ind_prod['date'])
    df_ind_prod['value'] = pd.to_numeric(df_ind_prod['value'], errors='coerce')
    df_ind_prod = df_ind_prod[['date', 'value']].set_index('date')
    df_ind_prod = df_ind_prod.dropna()

    df_ind_prod.rename(columns={'value': 'Industrial Production (Mom %)'}, inplace=True)
    df_ind_prod.index.name = "Date"

    print(df_ind_prod.head(10))

else:
    print('Failed to retrieve Yield Curve data.')
    print('Status Code:', response_ind_prod.status_code)
    print(response_ind_prod.text)

# Production- Industrial Production
series_id_ind_prod = 'INDPRO'
units_ind_prod = 'pch'        # No transformation #raw difference in yield (%) between the 10-year and 2-year U.S. Treasury bonds
frequency_ind_prod = 'm'      # Monthly
start_date_ind_prod = '1970-01-01'
end_date_ind_prod = '2025-04-23'

# URL and parameters
url_ind_prod = "https://api.stlouisfed.org/fred/series/observations"
params_ind_prod = {
    'series_id': series_id_ind_prod,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_ind_prod,
    'frequency': frequency_ind_prod,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_ind_prod = requests.get(url_ind_prod, params=params_ind_prod)

# Format response
if response_ind_prod.status_code == 200:
    data_ind_prod = response_ind_prod.json()
    df_ind_prod = pd.DataFrame(data_ind_prod['observations'])

    df_ind_prod['date'] = pd.to_datetime(df_ind_prod['date'])
    df_ind_prod['value'] = pd.to_numeric(df_ind_prod['value'], errors='coerce')
    df_ind_prod = df_ind_prod[['date', 'value']].set_index('date')
    df_ind_prod = df_ind_prod.dropna()

    df_ind_prod.rename(columns={'value': 'Industrial Production (Mom %)'}, inplace=True)
    df_ind_prod.index.name = "Date"

    print(df_ind_prod.head(10))

else:
    print('Failed to retrieve Yield Curve data.')
    print('Status Code:', response_ind_prod.status_code)
    print(response_ind_prod.text)

# All Employees Total Nonfarm
series_id_payems = 'PAYEMS'
units_payems = 'pch'        # No transformation #raw difference in yield (%) between the 10-year and 2-year U.S. Treasury bonds
frequency_payems = 'm'      # Monthly
start_date_payems = '1970-01-01'
end_date_payems = '2025-04-23'

# URL and parameters
url_payems = "https://api.stlouisfed.org/fred/series/observations"
params_payems = {
    'series_id': series_id_payems,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_payems,
    'frequency': frequency_payems,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_payems = requests.get(url_payems, params=params_payems)

# Format response
if response_payems.status_code == 200:
    data_payems = response_payems.json()
    df_payems = pd.DataFrame(data_payems['observations'])

    df_payems['date'] = pd.to_datetime(df_payems['date'])
    df_payems['value'] = pd.to_numeric(df_payems['value'], errors='coerce')
    df_payems = df_payems[['date', 'value']].set_index('date')
    df_payems = df_payems.dropna()

    df_payems.rename(columns={'value': ' Nonfarm Payrolls Index Mom (%)'}, inplace=True)
    df_payems.index.name = "Date"

    print(df_payems.head(10))

else:
    print('Nonfarm Payrolls Index data.')
    print('Status Code:', response_payems.status_code)
    print(response_payems.text)

# All Employees Total Nonfarm
series_unrate = 'UNRATE'
units_unrate = 'lin'        # No transformation #raw difference in yield (%) between the 10-year and 2-year U.S. Treasury bonds
frequency_unrate = 'm'      # Monthly
start_date_unrate = '1970-01-01'
end_date_unrate = '2025-04-23'

# URL and parameters
url_unrate = "https://api.stlouisfed.org/fred/series/observations"
params_unrate = {
    'series_id': series_unrate,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_unrate,
    'frequency': frequency_unrate,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_unrate = requests.get(url_unrate, params=params_unrate)

# Format response
if response_unrate.status_code == 200:
    data_unrate = response_unrate.json()
    df_unrate = pd.DataFrame(data_unrate['observations'])

    df_unrate['date'] = pd.to_datetime(df_unrate['date'])
    df_unrate['value'] = pd.to_numeric(df_unrate['value'], errors='coerce')
    df_unrate = df_unrate[['date', 'value']].set_index('date')
    df_unrate = df_unrate.dropna()

    df_unrate.rename(columns={'value': ' Nonfarm Payrolls Index Mom (%)'}, inplace=True)
    df_unrate.index.name = "Date"

    print(df_unrate.head(10))

else:
    print('Nonfarm Payrolls Index data.')
    print('Status Code:', response_unrate.status_code)
    print(response_unrate.text)

# All Employees Total Nonfarm
series_ret_sales = 'ADXTNO'
units_ret_sales = 'pch'        # No transformation #raw difference in yield (%) between the 10-year and 2-year U.S. Treasury bonds
frequency_ret_sales = 'm'      # Monthly
start_date_ret_sales = '1970-01-01'
end_date_ret_sales = '2025-04-23'

# URL and parameters
url_ret_sales = "https://api.stlouisfed.org/fred/series/observations"
params_ret_sales = {
    'series_id': series_ret_sales,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_ret_sales,
    'frequency': frequency_ret_sales,
   'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_ret_sales = requests.get(url_ret_sales, params=params_ret_sales)

# Format response
if response_ret_sales.status_code == 200:
    data_ret_sales = response_ret_sales.json()
    df_ret_sales = pd.DataFrame(data_ret_sales['observations'])

    df_ret_sales['date'] = pd.to_datetime(df_ret_sales['date'])
    df_ret_sales['value'] = pd.to_numeric(df_ret_sales['value'], errors='coerce')
    df_ret_sales = df_ret_sales[['date', 'value']].set_index('date')
    df_ret_sales = df_ret_sales.dropna()

    df_ret_sales.rename(columns={'value': ' Advance Retail Sales Index Mom (%)'}, inplace=True)
    df_ret_sales.index.name = "Date"

    print(df_unrate.head(10))

else:
    print('Advance Retail Sales Index data.')
    print('Status Code:', response_unrate.status_code)
    print(response_unrate.text)

# All Employees Total Nonfarm
series_rpi = 'RPI'
units_rpi = 'pch'        # No transformation #raw difference in yield (%) between the 10-year and 2-year U.S. Treasury bonds
frequency_rpi = 'm'      # Monthly
start_date_rpi = '1970-01-01'
end_date_rpi = '2025-04-23'

# URL and parameters
url_rpi = "https://api.stlouisfed.org/fred/series/observations"
params_rpi = {
    'series_id': series_rpi,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_rpi,
    'frequency': frequency_rpi,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_rpi = requests.get(url_rpi, params=params_rpi)

# Format response
if response_rpi.status_code == 200:
    data_rpi = response_rpi.json()
    df_rpi = pd.DataFrame(data_rpi['observations'])

    df_rpi['date'] = pd.to_datetime(df_rpi['date'])
    df_rpi['value'] = pd.to_numeric(df_rpi['value'], errors='coerce')
    df_rpi = df_rpi[['date', 'value']].set_index('date')
    df_rpi = df_rpi.dropna()

    df_rpi.rename(columns={'value': 'Real Personal Income MoM (%)'}, inplace=True)
    df_rpi.index.name = "Date"

    print(df_rpi.head(10))

else:
    print('Failed to retrieve Real Personal Income data.')
    print('Status Code:', response_rpi.status_code)
    print(response_rpi.text)

# All Employees Total Nonfarm
series_real_gdp = 'GDPC1'
units_real_gdp = 'pch'        # No transformation #raw difference in yield (%) between the 10-year and 2-year U.S. Treasury bonds
frequency_real_gdp = 'q'      # Monthly
start_date_real_gdp = '1970-01-01'
end_date_real_gdp = '2025-04-23'

# URL and parameters
url_real_gdp = "https://api.stlouisfed.org/fred/series/observations"
params_real_gdp = {
    'series_id': series_real_gdp,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_real_gdp,
    'frequency': frequency_real_gdp,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_real_gdp = requests.get(url_real_gdp, params=params_real_gdp)

# Format response
if response_real_gdp.status_code == 200:
    data_real_gdp = response_real_gdp.json()
    df_real_gdp = pd.DataFrame(data_real_gdp['observations'])

    df_real_gdp['date'] = pd.to_datetime(df_real_gdp['date'])
    df_real_gdp['value'] = pd.to_numeric(df_real_gdp['value'], errors='coerce')
    df_real_gdp = df_real_gdp[['date', 'value']].set_index('date')
    df_real_gdp = df_real_gdp.dropna()

    df_real_gdp.rename(columns={'value': 'Real GDP QoQ (%)'}, inplace=True)
    df_real_gdp.index.name = "Date"

    print(df_real_gdp.head(10))

else:
    print('Real GDP data.')
    print('Status Code:', response_real_gdp.status_code)
    print(response_real_gdp.text)

# Production- Industrial Production
series_id_capacity_utilization = 'INDPRO'
units_capacity_utilization = 'pch'        # No transformation #raw difference in yield (%) between the 10-year and 2-year U.S. Treasury bonds
frequency_capacity_utilization = 'm'      # Monthly
start_date_capacity_utilization = '1970-01-01'
end_date_capacity_utilization = '2025-04-23'

# URL and parameters
url_capacity_utilization = "https://api.stlouisfed.org/fred/series/observations"
params_capacity_utilization = {
    'series_id': series_id_capacity_utilization,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_capacity_utilization,
    'frequency': frequency_capacity_utilization,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_capacity_utilization = requests.get(url_capacity_utilization, params=params_capacity_utilization)

# Format response
if response_capacity_utilization.status_code == 200:
    data_capacity_utilization = response_capacity_utilization.json()
    df_capacity_utilization = pd.DataFrame(data_capacity_utilization['observations'])

    df_capacity_utilization['date'] = pd.to_datetime(df_capacity_utilization['date'])
    df_capacity_utilization['value'] = pd.to_numeric(df_capacity_utilization['value'], errors='coerce')
    df_capacity_utilization = df_capacity_utilization[['date', 'value']].set_index('date')
    df_capacity_utilization = df_capacity_utilization.dropna()

    df_capacity_utilization.rename(columns={'value': ' Capacity Utilization Index Mom (%)'}, inplace=True)
    df_capacity_utilization.index.name = "Date"

    print(df_capacity_utilization.head(10))

else:
    print('Failed to retrieve Capacity Utilization Index data.')
    print('Status Code:', response_capacity_utilization.status_code)
    print(response_capacity_utilization.text)

# All Employees Total Nonfarm
series_dg_ex_trans = 'RSAFS'
units_dg_ex_trans = 'pch'        # No transformation #raw difference in yield (%) between the 10-year and 2-year U.S. Treasury bonds
frequency_dg_ex_trans = 'm'      # Monthly
start_date_dg_ex_trans = '1970-01-01'
end_date_dg_ex_trans = '2025-04-23'

# URL and parameters
url_dg_ex_trans = "https://api.stlouisfed.org/fred/series/observations"
params_dg_ex_trans = {
    'series_id': series_dg_ex_trans,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_dg_ex_trans,
    'frequency': frequency_dg_ex_trans,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_dg_ex_trans = requests.get(url_dg_ex_trans, params=params_dg_ex_trans)

# Format response
if response_dg_ex_trans.status_code == 200:
    data_dg_ex_trans = response_dg_ex_trans.json()
    df_dg_ex_trans = pd.DataFrame(data_dg_ex_trans['observations'])

    df_dg_ex_trans['date'] = pd.to_datetime(df_dg_ex_trans['date'])
    df_dg_ex_trans['value'] = pd.to_numeric(df_dg_ex_trans['value'], errors='coerce')
    df_dg_ex_trans = df_dg_ex_trans[['date', 'value']].set_index('date')
    df_dg_ex_trans = df_dg_ex_trans.dropna()

    df_dg_ex_trans.rename(columns={'value': 'Manufacturers New Orders Index Mom (%)'}, inplace=True)
    df_dg_ex_trans.index.name = "Date"

    print(df_dg_ex_trans.head(10))

else:
    print('Manufacturers New Orders Index data.')
    print('Status Code:', response_dg_ex_trans.status_code)
    print(response_dg_ex_trans.text)

# ---- STEP 1: Concatenate all Growth Theme indicators ----
df_growth_data = pd.concat([
    df_ind_prod,                   # Industrial Production
    df_capacity_utilization,      # Capacity Utilization
    df_payems,                    # Nonfarm Payrolls (MoM %)
    df_unrate,                    # Unemployment Rate
    df_ret_sales,                 # Retail Sales (MoM %)
    df_dg_ex_trans,               # Durable Goods Orders (ex-transportation)
    df_real_gdp,               # Real GDP Monthly Proxy (spread evenly over 3 months)
    df_rpi                        # Real Personal Income (MoM %)
], axis=1)

# ---- STEP 2: Drop rows with missing values (e.g., incomplete early dates) ----
first_valid_date = df_growth_data.dropna().index.min()
df_growth_data = df_growth_data.loc[first_valid_date:]

# ---- STEP 3: Forward-fill quarterly values like GDP if needed ----
df_growth_data = df_growth_data.ffill()

# ---- STEP 4: Round only numeric columns safely ----
numeric_cols = df_growth_data.select_dtypes(include=['float64', 'int64']).columns
for col in numeric_cols:
    df_growth_data[col] = df_growth_data[col].round(2)

# ---- STEP 5: Reset index and name it 'Date' for clean presentation ----
df_growth_data = df_growth_data.reset_index()
df_growth_data.rename(columns={'index': 'Date'}, inplace=True)

# ---- STEP 6: Preview final cleaned dataset ----
print(df_growth_data.head())

"""# Liquidity Data"""

# Liquidity - M2 Money Supply
series_id_m2 = 'M2SL'
units_m2 = 'pc1'        # Percent change (Month-over-Month %)
frequency_m2 = 'm'      # Monthly
start_date_m2 = '1970-01-01'
end_date_m2 = '2025-04-23'

# URL and parameters
url_m2 = "https://api.stlouisfed.org/fred/series/observations"
params_m2 = {
    'series_id': series_id_m2,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_m2,
    'frequency': frequency_m2,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_m2 = requests.get(url_m2, params=params_m2)

# Format response
if response_m2.status_code == 200:
    data_m2 = response_m2.json()
    df_m2 = pd.DataFrame(data_m2['observations'])

    df_m2['date'] = pd.to_datetime(df_m2['date'])
    df_m2['value'] = pd.to_numeric(df_m2['value'], errors='coerce')
    df_m2 = df_m2[['date', 'value']].set_index('date')
    df_m2 = df_m2.dropna()

    df_m2.rename(columns={'value': 'M2 MoM %'}, inplace=True)
    df_m2.index.name = "Date"

    print(df_m2.head(10))

else:
    print('Failed to retrieve M2 data.')
    print('Status Code:', response_m2.status_code)
    print(response_m2.text)

# Liquidity - Chicago Fed National Financial Conditions Index (NFCI)
series_id_NFCI = 'NFCI'
units_NFCI = 'lin'        # No transformation
frequency_NFCI = 'm'      # Weekly
start_date_NFCI = '1970-01-01'
end_date_NFCI = '2025-04-23'

# URL and parameters
url_NFCI = "https://api.stlouisfed.org/fred/series/observations"
params_NFCI = {
    'series_id': series_id_NFCI,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_NFCI,
    'frequency': frequency_NFCI,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_NFCI = requests.get(url_NFCI, params=params_NFCI)

# Format response
if response_NFCI.status_code == 200:
    data_NFCI = response_NFCI.json()
    df_NFCI = pd.DataFrame(data_NFCI['observations'])

    df_NFCI['date'] = pd.to_datetime(df_NFCI['date'])
    df_NFCI['value'] = pd.to_numeric(df_NFCI['value'], errors='coerce')
    df_NFCI = df_NFCI[['date', 'value']].set_index('date')
    df_NFCI = df_NFCI.dropna()

    df_NFCI.rename(columns={'value': 'NFCI (Financial Conditions Index)'}, inplace=True)
    df_NFCI.index.name = "Date"

    print(df_NFCI.head(10))

else:
    print('Failed to retrieve NFCI data.')
    print('Status Code:', response_NFCI.status_code)
    print(response_NFCI.text)

# Liquidity - 10-Year Treasury Yield (GS10)
series_id_GS10 = 'GS10'
units_GS10 = 'lin'        # Percent change (Month-over-Month %)
frequency_GS10 = 'm'      # Monthly
start_date_GS10 = '1970-01-01'
end_date_GS10 = '2025-04-23'

# URL and parameters
url_GS10 = "https://api.stlouisfed.org/fred/series/observations"
params_GS10 = {
    'series_id': series_id_GS10,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_GS10,
    'frequency': frequency_GS10,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_GS10 = requests.get(url_GS10, params=params_GS10)

# Format response
if response_GS10.status_code == 200:
    data_GS10 = response_GS10.json()
    df_GS10 = pd.DataFrame(data_GS10['observations'])

    df_GS10['date'] = pd.to_datetime(df_GS10['date'])
    df_GS10['value'] = pd.to_numeric(df_GS10['value'], errors='coerce')
    df_GS10 = df_GS10[['date', 'value']].set_index('date')
    df_GS10 = df_GS10.dropna()

    df_GS10.rename(columns={'value': '10Y Treasury Yield MoM %'}, inplace=True)
    df_GS10.index.name = "Date"

    print(df_GS10.head(10))

else:
    print('Failed to retrieve GS10 data.')
    print('Status Code:', response_GS10.status_code)
    print(response_GS10.text)

# Treasury Bill Rate - 3-Month (Secondary Market)
series_id_tb3ms = 'TB3MS'
units_tb3ms = 'lin'        # Level data (no transformation)
frequency_tb3ms = 'm'      # Monthly
start_date_tb3ms = '1970-01-01'
end_date_tb3ms = '2025-04-23'

# URL and parameters
url_tb3ms = "https://api.stlouisfed.org/fred/series/observations"
params_tb3ms = {
    'series_id': series_id_tb3ms,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_tb3ms,
    'frequency': frequency_tb3ms,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_tb3ms = requests.get(url_tb3ms, params=params_tb3ms)

# Format response
if response_tb3ms.status_code == 200:
    data_tb3ms = response_tb3ms.json()
    df_tb3ms = pd.DataFrame(data_tb3ms['observations'])

    df_tb3ms['date'] = pd.to_datetime(df_tb3ms['date'])
    df_tb3ms['value'] = pd.to_numeric(df_tb3ms['value'], errors='coerce')
    df_tb3ms = df_tb3ms[['date', 'value']].set_index('date')
    df_tb3ms = df_tb3ms.dropna()

    df_tb3ms.rename(columns={'value': '3-Month T-Bill Rate (%)'}, inplace=True)
    df_tb3ms.index.name = "Date"

    print(df_tb3ms.head(10))

else:
    print('Failed to retrieve 3-Month T-Bill Rate data.')
    print('Status Code:', response_tb3ms.status_code)
    print(response_tb3ms.text)

# Merge the two dataframes on the Date index
df_10Y_3M_T_Spread = df_GS10.merge(df_tb3ms, how='inner', left_index=True, right_index=True)

# Subtract 3-Month T-Bill Rate from 10-Year Treasury Yield
df_10Y_3M_T_Spread['10Y 3M Treasury Spread'] = df_10Y_3M_T_Spread['10Y Treasury Yield MoM %'] - df_10Y_3M_T_Spread['3-Month T-Bill Rate (%)']

# Optional: round for readability
df_10Y_3M_T_Spread = df_10Y_3M_T_Spread.round(2)

# Preview result
print(df_10Y_3M_T_Spread.head(10))

"""
import pandas as pd

# Load the Excel file
df_ted = pd.read_excel('Ted Spread.xlsx')  # Update path if needed

# Convert the 'Date' column to datetime format
df_ted['Date'] = pd.to_datetime(df_ted['Date'])

# Shift dates forward by 1 day
df_ted['Date'] = df_ted['Date'] + pd.Timedelta(days=1)

# Set 'Date' as index
df_ted = df_ted.set_index('Date')

# Optionally rename the column for consistency
df_ted.rename(columns={'Ted Spread': 'TED Spread (bps)'}, inplace=True)

# View result
print(df_ted.head())
"""

# ---- STEP 1: Concatenate all Liquidity Theme indicators ----
df_liquidity_data = pd.concat([
    df_m2,
    df_NFCI,
    df_10Y_3M_T_Spread,
    #df_ted,
], axis=1)

# ---- STEP 2: Convert index to datetime (just to be safe) ----
df_liquidity_data.index = pd.to_datetime(df_liquidity_data.index)

# ---- STEP 3: Forward-fill (important for series like TED Spread or NFCI) ----
df_liquidity_data = df_liquidity_data.ffill()

# ---- STEP 4: Drop only rows where ALL columns are missing ----
#df_liquidity_data = df_liquidity_data.dropna(how='all')

# ---- STEP 5: Optionally drop rows where most columns are missing (e.g., 3 out of 4 are NaN) ----
first_valid_date = df_liquidity_data.dropna().index.min()
df_liquidity_data = df_liquidity_data.loc[first_valid_date:]

# ---- STEP 6: Round numeric columns for readability ----
numeric_cols = df_liquidity_data.select_dtypes(include=['float64', 'int64']).columns
df_liquidity_data[numeric_cols] = df_liquidity_data[numeric_cols].round(2)

# ---- STEP 7: Reset index and rename it for presentation ----
df_liquidity_data = df_liquidity_data.reset_index()
df_liquidity_data.rename(columns={'index': 'Date'}, inplace=True)

# ---- STEP 8: Inspect result ----
print(df_liquidity_data.head())

#X-66488400



"""
# Policy Data"""

# Monetary Policy - Effective Federal Funds Rate
series_id_FEDFUNDS = 'FEDFUNDS'
units_FEDFUNDS = 'lin'        # No transformation (level data)
frequency_FEDFUNDS = 'm'      # Monthly
start_date_FEDFUNDS = '1970-01-01'
end_date_FEDFUNDS = '2025-04-23'

# URL and parameters
url_FEDFUNDS = "https://api.stlouisfed.org/fred/series/observations"
params_FEDFUNDS = {
    'series_id': series_id_FEDFUNDS,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_FEDFUNDS,
    'frequency': frequency_FEDFUNDS,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_FEDFUNDS = requests.get(url_FEDFUNDS, params=params_FEDFUNDS)

# Format response
if response_FEDFUNDS.status_code == 200:
    data_FEDFUNDS = response_FEDFUNDS.json()
    df_FEDFUNDS = pd.DataFrame(data_FEDFUNDS['observations'])

    df_FEDFUNDS['date'] = pd.to_datetime(df_FEDFUNDS['date'])
    df_FEDFUNDS['value'] = pd.to_numeric(df_FEDFUNDS['value'], errors='coerce')
    df_FEDFUNDS = df_FEDFUNDS[['date', 'value']].set_index('date')
    df_FEDFUNDS = df_FEDFUNDS.dropna()

    df_FEDFUNDS.rename(columns={'value': 'Fed Funds Rate (%)'}, inplace=True)
    df_FEDFUNDS.index.name = "Date"

    print(df_FEDFUNDS.head(10))

else:
    print('Failed to retrieve Fed Funds data.')
    print('Status Code:', response_FEDFUNDS.status_code)
    print(response_FEDFUNDS.text)

# Core CPI - Core Consumer Price Index (YoY % or desired units)
series_id_core_cpi = 'CPILFESL'
units_core_cpi = 'pch'        # Percent change from previous period (you can adjust to 'pc1' for YoY if needed)
frequency_core_cpi = 'm'      # Monthly
start_date_core_cpi = '1970-01-01'
end_date_core_cpi = '2025-04-23'

# URL and parameters
url_core_cpi = "https://api.stlouisfed.org/fred/series/observations"
params_core_cpi = {
    'series_id': series_id_core_cpi,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_core_cpi,
    'frequency': frequency_core_cpi,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_core_cpi = requests.get(url_core_cpi, params=params_core_cpi)

# Format response
if response_core_cpi.status_code == 200:
    data_core_cpi = response_core_cpi.json()
    df_core_cpi = pd.DataFrame(data_core_cpi['observations'])

    df_core_cpi['date'] = pd.to_datetime(df_core_cpi['date'])
    df_core_cpi['value'] = pd.to_numeric(df_core_cpi['value'], errors='coerce')
    df_core_cpi = df_core_cpi[['date', 'value']].set_index('date')
    df_core_cpi = df_core_cpi.dropna()

    df_core_cpi.rename(columns={'value': 'Core CPI (MoM %)'}, inplace=True)
    df_core_cpi.index.name = "Date"

    print(df_core_cpi.head(10))

else:
    print('Failed to retrieve Core CPI data.')
    print('Status Code:', response_core_cpi.status_code)
    print(response_core_cpi.text)

# Merge the two dataframes on the Date index
df_real_rate = df_FEDFUNDS.merge(df_core_cpi, how='inner', left_index=True, right_index=True)

# Subtract Core CPI from Fed Funds to compute the real rate
df_real_rate['Real Fed Funds Rate (%)'] = df_real_rate['Fed Funds Rate (%)'] - df_real_rate['Core CPI (MoM %)']

# Optional: round for readability
df_real_rate = df_real_rate.round(2)

# Preview result
print(df_real_rate.head(10))

# Policy - Fed Balance Sheet (Total Assets)
series_id_WALCL = 'WALCL'
units_WALCL = 'pch'        # Percent change (Month-over-Month %)
frequency_WALCL = 'm'      # Monthly
start_date_WALCL = '1970-01-01'
end_date_WALCL = '2025-04-23'

# URL and parameters
url_WALCL = "https://api.stlouisfed.org/fred/series/observations"
params_WALCL = {
    'series_id': series_id_WALCL,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_WALCL,
    'frequency': frequency_WALCL,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_WALCL = requests.get(url_WALCL, params=params_WALCL)

# Format response
if response_WALCL.status_code == 200:
    data_WALCL = response_WALCL.json()
    df_WALCL = pd.DataFrame(data_WALCL['observations'])

    df_WALCL['date'] = pd.to_datetime(df_WALCL['date'])
    df_WALCL['value'] = pd.to_numeric(df_WALCL['value'], errors='coerce')
    df_WALCL = df_WALCL[['date', 'value']].set_index('date')
    df_WALCL = df_WALCL.dropna()

    df_WALCL.rename(columns={'value': 'Fed Balance Sheet MoM %'}, inplace=True)
    df_WALCL.index.name = "Date"

    print(df_WALCL.head(10))

else:
    print('Failed to retrieve WALCL data.')
    print('Status Code:', response_WALCL.status_code)
    print(response_WALCL.text)

# Fiscal Policy - Federal Budget Deficit as % of GDP
series_id_fiscal = 'FYFSGDA188S'
units_fiscal = 'lin'        # Level data (not percent change)
frequency_fiscal = 'a'      # Quarterly
start_date_fiscal = '1970-01-01'
end_date_fiscal = '2025-04-23'

# URL and parameters
url_fiscal = "https://api.stlouisfed.org/fred/series/observations"
params_fiscal = {
    'series_id': series_id_fiscal,
    'api_key': api_key,
    'file_type': 'json',
    'units': units_fiscal,
    'frequency': frequency_fiscal,
    'observation_start': start_date,
    'observation_end': end_date
}

# Make the request
response_fiscal = requests.get(url_fiscal, params=params_fiscal)

# Format response
if response_fiscal.status_code == 200:
    data_fiscal = response_fiscal.json()
    df_fiscal = pd.DataFrame(data_fiscal['observations'])

    df_fiscal['date'] = pd.to_datetime(df_fiscal['date'])
    df_fiscal['value'] = pd.to_numeric(df_fiscal['value'], errors='coerce')
    df_fiscal = df_fiscal[['date', 'value']].set_index('date')
    df_fiscal = df_fiscal.dropna()

    df_fiscal.rename(columns={'value': 'Federal Budget Deficit (% GDP)'}, inplace=True)
    df_fiscal.index.name = "Date"

    print(df_fiscal.head(10))

else:
    print('Failed to retrieve fiscal data.')
    print('Status Code:', response_fiscal.status_code)
    print(response_fiscal.text)

# ---- STEP 1: Concatenate all Growth Theme indicators ----
df_policy_data = pd.concat([
    df_fiscal,
    df_WALCL,
    df_real_rate,
    df_FEDFUNDS,
], axis=1)

# ---- STEP 2: Drop rows with missing values (e.g., incomplete early dates) ----
first_valid_date = df_policy_data.dropna().index.min()
df_policy_data = df_policy_data.loc[first_valid_date:]

# ---- STEP 3: Forward-fill quarterly values like GDP if needed ----
df_policy_data = df_policy_data.ffill()

# ---- STEP 4: Round only numeric columns safely ----
numeric_cols = df_policy_data.select_dtypes(include=['float64', 'int64']).columns
for col in numeric_cols:
    df_policy_data[col] = df_policy_data[col].round(2)

# ---- STEP 5: Reset index and name it 'Date' for clean presentation ----
df_policy_data = df_policy_data.reset_index()
df_policy_data.rename(columns={'index': 'Date'}, inplace=True)

# ---- STEP 6: Preview final cleaned dataset ----
print(df_policy_data.head())

"""# CSV Datas"""

df_liquidity_data.to_csv("liquidity_data.csv", index = False)
df_growth_data.to_csv("growth_data.csv", index = False)
df_inflation_data.to_csv("inflation_data.csv", index = False)
df_policy_data.to_csv("policy_data.csv", index = False)

"""# Z score changer"""

import pandas as pd
from sklearn.preprocessing import StandardScaler

# 1. Load the dataset
df_growth = pd.read_csv("growth_data.csv", index_col="Date", parse_dates=True)

# 2. Apply Z-score transformation using StandardScaler
scaler_growth = StandardScaler()
X_scaled_growth = scaler_growth.fit_transform(df_growth)

# 3. Convert back to a DataFrame with the same index and columns
df_zscore_growth = pd.DataFrame(X_scaled_growth, index=df_growth.index, columns=df_growth.columns)

# 4. Reset index so 'Date' becomes a column
df_zscore_growth = df_zscore_growth.reset_index()

# 5. Define the labeling function (5-category framework)
def label_zscore(value):
    if value >= 1.5:
        return 'Very Hot'
    elif value >= 0.5:
        return 'Hot'
    elif value <= -1.5:
        return 'Very Cold'
    elif value <= -0.5:
        return 'Cold'
    else:
        return 'Neutral'

# 6. Apply labels to all Z-score columns (excluding 'Date')
for col in df_zscore_growth.columns:
    if col != 'Date':
        label_col = col + "_Label"
        df_zscore_growth[label_col] = df_zscore_growth[col].apply(label_zscore)

# 7. Preview the final labeled DataFrame
print(df_zscore_growth.head())

import pandas as pd
from sklearn.preprocessing import StandardScaler

# 1. Load your clean monthly policy indicators
df_policy = pd.read_csv("policy_data.csv", index_col="Date", parse_dates=True)

# 2. Apply Z-score transformation
scaler_policy = StandardScaler()
X_scaled_policy = scaler_policy.fit_transform(df_policy)

# 3. Convert back to a DataFrame with the same index and column names
df_zscore_policy = pd.DataFrame(X_scaled_policy, index=df_policy.index, columns=df_policy.columns)

# 4. Reset index so 'Date' becomes a column
df_zscore_policy = df_zscore_policy.reset_index()

# 5. Define the labeling function (5-category tag)
def label_zscore(value):
    if value >= 1.5:
        return 'Very Hot'
    elif value >= 0.5:
        return 'Hot'
    elif value <= -1.5:
        return 'Very Cold'
    elif value <= -0.5:
        return 'Cold'
    else:
        return 'Neutral'

# 6. Apply labels to each Z-score column
for col in df_zscore_policy.columns:
    if col != 'Date':
        label_col = col + "_Label"
        df_zscore_policy[label_col] = df_zscore_policy[col].apply(label_zscore)

# 7. Preview the final DataFrame
print(df_zscore_policy.head())

import pandas as pd
from sklearn.preprocessing import StandardScaler

# 1. Load your clean monthly inflation indicators
df_inflation = pd.read_csv("inflation_data.csv", index_col="Date", parse_dates=True)

# 2. Apply Z-score transformation
scaler_inflation = StandardScaler()
X_scaled_inflation = scaler_inflation.fit_transform(df_inflation)

# 3. Convert back to a DataFrame with the same index and column names
df_zscore_inflation = pd.DataFrame(X_scaled_inflation, index=df_inflation.index, columns=df_inflation.columns)

# 4. Reset index so 'Date' becomes a column
df_zscore_inflation = df_zscore_inflation.reset_index()

# 5. Define the labeling function (5-category tag)
def label_zscore(value):
    if value >= 1.5:
        return 'Very Hot'
    elif value >= 0.5:
        return 'Hot'
    elif value <= -1.5:
        return 'Very Cold'
    elif value <= -0.5:
        return 'Cold'
    else:
        return 'Neutral'

# 6. Apply labels to each Z-score column
for col in df_zscore_inflation.columns:
    if col != 'Date':
        label_col = col + "_Label"
        df_zscore_inflation[label_col] = df_zscore_inflation[col].apply(label_zscore)

# 7. Preview the final DataFrame
print(df_zscore_inflation.head())

import pandas as pd
from sklearn.preprocessing import StandardScaler

# 1. Load your clean monthly liquidity indicators
df_liquidity = pd.read_csv("liquidity_data.csv", index_col="Date", parse_dates=True)

# 2. Apply Z-score transformation
scaler_liquidity = StandardScaler()
X_scaled_liquidity = scaler_liquidity.fit_transform(df_liquidity)

# 3. Convert back to a DataFrame with the same index and column names
df_zscore_liquidity = pd.DataFrame(X_scaled_liquidity, index=df_liquidity.index, columns=df_liquidity.columns)

# 4. Reset index so 'Date' becomes a column
df_zscore_liquidity = df_zscore_liquidity.reset_index()

# 5. Define the labeling function (5-category tag)
def label_zscore(value):
    if value >= 1.5:
        return 'Very Hot'
    elif value >= 0.5:
        return 'Hot'
    elif value <= -1.5:
        return 'Very Cold'
    elif value <= -0.5:
        return 'Cold'
    else:
        return 'Neutral'

# 6. Apply labels to each Z-score column
for col in df_zscore_liquidity.columns:
    if col != 'Date':
        label_col = col + "_Label"
        df_zscore_liquidity[label_col] = df_zscore_liquidity[col].apply(label_zscore)

# 7. Preview the final DataFrame
print(df_zscore_liquidity.head())

df_zscore_policy.to_csv("policy_zscores_labeled.csv", index=False)
df_zscore_inflation.to_csv("inflation_zscores_labeled.csv", index=False)
df_zscore_growth.to_csv("growth_zscores_labeled.csv", index=False)
df_zscore_liquidity.to_csv("liquidity_zscores_labeled.csv", index=False)

"""# Inflation Weights"""

import pandas as pd

df = pd.read_csv("inflation_zscores_labeled.csv")

# Show column names clearly
for col in df.columns:
    print(f"'{col}'")

df.columns = df.columns.str.strip()

df.rename(columns={
    'CPI MoM %': 'CPI_Z',
    'Core CPI (MoM %)': 'Core_CPI_Z',
    'PPI (MoM %)': 'PPI_Z',
    'Consumer Sentiment Index (UMich)': 'UMich_Infl_Z'
}, inplace=True)

def normalized_contribution(z, weight, cap=2.0):
    # Cap Z-score between -2 and +2
    z = max(min(z, cap), -cap)
    # Normalize to 0–1 scale where -2 → 0, 0 → 0.5, +2 → 1
    scaled = (z + cap) / (2 * cap)
    return scaled * weight

# Headline Inflation
df['Headline_Inflation_SubTheme_Score'] = df['CPI_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

# Core Inflation
df['Core_Inflation_SubTheme_Score'] = df['Core_CPI_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

# Cost Pressures
df['Cost_Pressures_SubTheme_Score'] = df['PPI_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

# Inflation Expectations (from UMich sentiment)
df['Inflation_Expectations_SubTheme_Score'] = df['UMich_Infl_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

weights_inflation = {
    'Headline_Inflation_SubTheme_Score': 0.3,
    'Core_Inflation_SubTheme_Score': 0.3,
    'Cost_Pressures_SubTheme_Score': 0.2,
    'Inflation_Expectations_SubTheme_Score': 0.2
}

df['Inflation_Theme_Score'] = sum(
    df[col] * weight for col, weight in weights_inflation.items()
).round(2)

print(df[['Date', 'Inflation_Theme_Score']].head())

df[['Date',
    'Headline_Inflation_SubTheme_Score',
    'Core_Inflation_SubTheme_Score',
    'Cost_Pressures_SubTheme_Score',
    'Inflation_Expectations_SubTheme_Score',
    'Inflation_Theme_Score',
]].to_csv("inflation_theme_output.csv", index=False)

print(df['UMich_Infl_Z'].describe())
print(df['UMich_Infl_Z'].head(10))

df['Inflation_Expectations_SubTheme_Score'] = df['UMich_Infl_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

"""# Growth Weights"""

import pandas as pd

# Load your CSV
df = pd.read_csv("growth_zscores_labeled.csv")

# Print all column names
print(df.columns.tolist())

import pandas as pd

df = pd.read_csv("growth_data.csv")

# Show column names clearly
for col in df.columns:
    print(f"'{col}'")

import pandas as pd

# Load the data
df = pd.read_csv("growth_data.csv")

# Step 1: Strip leading/trailing whitespace
df.columns = df.columns.str.strip()

# Step 2: Rename all columns to clean, code-friendly names
df.rename(columns={
    'Industrial Production (Mom %)': 'Industrial_Production_Z',
    'Capacity Utilization Index Mom (%)': 'Capacity_Utilization_Z',
    'Nonfarm Payrolls Index Mom (%)': 'Nonfarm_Payrolls_Z',
    'Nonfarm Payrolls Index Mom (%).1': 'Unemployment_Rate_Z',
    'Advance Retail Sales Index Mom (%)': 'Retail_Sales_Z',
    'Manufacturers New Orders Index Mom (%)': 'Durable_Goods_Orders_Z',
    'Real GDP QoQ (%)': 'Real_GDP_Z',
    'Real Personal Income MoM (%)': 'Real_Income_Z'
}, inplace=True)

# Check that it worked
print(df.columns.tolist())

# Define sub-theme weights
weights_production = {
    'Industrial_Production_Z': 0.6,
    'Capacity_Utilization_Z': 0.4
}

# Define your scoring function
def normalized_contribution(z, weight, cap=2.0):
    z = max(min(z, cap), -cap)               # Cap between -2 and +2
    scaled = (z + cap) / (2 * cap)           # Scale to 0–1
    return scaled * weight                   # Apply weight

# Apply the function and calculate the Production Sub-Theme Score
df['Production_SubTheme_Score'] = (
    df['Industrial_Production_Z'].apply(lambda z: normalized_contribution(z, 0.6)) +
    df['Capacity_Utilization_Z'].apply(lambda z: normalized_contribution(z, 0.4))
) * 100  # Final score out of 100

# Round it for display
df['Production_SubTheme_Score'] = df['Production_SubTheme_Score'].round(2)

# Preview the result
print(df[['Date', 'Production_SubTheme_Score']].head())

weights_demand = {
    'Retail_Sales_Z': 0.6,
    'Real_Income_Z': 0.4
}

df['Demand_SubTheme_Score'] = (
    df['Retail_Sales_Z'].apply(lambda z: normalized_contribution(z, 0.6)) +
    df['Real_Income_Z'].apply(lambda z: normalized_contribution(z, 0.4))
) * 100

df['Demand_SubTheme_Score'] = df['Demand_SubTheme_Score'].round(2)

weights_labor = {
    'Nonfarm_Payrolls_Z': 0.7,
    'Unemployment_Rate_Z': 0.3
}

df['Labor_SubTheme_Score'] = (
    df['Nonfarm_Payrolls_Z'].apply(lambda z: normalized_contribution(z, 0.7)) +
    df['Unemployment_Rate_Z'].apply(lambda z: normalized_contribution(z, 0.3))
) * 100

df['Labor_SubTheme_Score'] = df['Labor_SubTheme_Score'].round(2)

df['Investment_SubTheme_Score'] = df['Durable_Goods_Orders_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100
df['Investment_SubTheme_Score'] = df['Investment_SubTheme_Score'].round(2)

df['GDP_SubTheme_Score'] = df['Real_GDP_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100
df['GDP_SubTheme_Score'] = df['GDP_SubTheme_Score'].round(2)

# Demand Sub-Theme weights
weights_demand = {
    'Retail_Sales_Z': 0.6,
    'Real_Income_Z': 0.4
}

# Calculate Demand Sub-Theme Score
df['Demand_SubTheme_Score'] = (
    df['Retail_Sales_Z'].apply(lambda z: normalized_contribution(z, 0.6)) +
    df['Real_Income_Z'].apply(lambda z: normalized_contribution(z, 0.4))
) * 100

df['Demand_SubTheme_Score'] = df['Demand_SubTheme_Score'].round(2)

df['Demand_SubTheme_Score'] = (
    df['Retail_Sales_Z'].apply(lambda z: normalized_contribution(z, 0.6)) +
    df['Real_Income_Z'].apply(lambda z: normalized_contribution(z, 0.4))
) * 100

df['Demand_SubTheme_Score'] = df['Demand_SubTheme_Score'].round(2)

# Growth sub-theme weights
growth_theme_weights = {
    'Production_SubTheme_Score': 0.20,
    'Labor_SubTheme_Score': 0.30,
    'Demand_SubTheme_Score': 0.25,
    'Investment_SubTheme_Score': 0.15,
    'GDP_SubTheme_Score': 0.10
}

# Compute weighted sum of sub-theme scores
df['Growth_Theme_Score'] = sum(
    df[col] * weight for col, weight in growth_theme_weights.items()
).round(2)

growth_theme_weights = {
    'Production_SubTheme_Score': 0.20,
    'Labor_SubTheme_Score': 0.30,
    'Demand_SubTheme_Score': 0.25,
    'Investment_SubTheme_Score': 0.15,
    'GDP_SubTheme_Score': 0.10
}

df['Growth_Theme_Score'] = sum(
    df[col] * weight for col, weight in growth_theme_weights.items()
).round(2)

df[['Date',
    'Production_SubTheme_Score',
    'Labor_SubTheme_Score',
    'Demand_SubTheme_Score',
    'Investment_SubTheme_Score',
    'GDP_SubTheme_Score',
    'Growth_Theme_Score']].to_csv("growth_theme_output.csv", index=False)

"""# Liquidity Weights"""

import pandas as pd

df = pd.read_csv("liquidity_zscores_labeled.csv")

# Show column names clearly
for col in df.columns:
    print(f"'{col}'")

df.columns = df.columns.str.strip()

df.rename(columns={
    'M2 MoM %': 'M2_MoM_Z',
    'NFCI (Financial Conditions Index)': 'NFCI_Z',
    '10Y 3M Treasury Spread': 'YieldCurve_10Y3M_Z',
    'TED Spread (bps)': 'TED_Spread_Z'
}, inplace=True)

def normalized_contribution(z, weight, cap=2.0):
    z = max(min(z, cap), -cap)        # Cap between -2 and +2
    scaled = (z + cap) / (2 * cap)    # Normalize to 0–1 scale
    return scaled * weight

df['MoneySupply_SubTheme_Score'] = df['M2_MoM_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

#df['Credit_SubTheme_Score'] = df['TED_Spread_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

df['Financial_Tightness_SubTheme_Score'] = df['NFCI_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

df['YieldCurve_SubTheme_Score'] = df['YieldCurve_10Y3M_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

weights_liquidity = {
    'MoneySupply_SubTheme_Score': 0.34,
    #'Credit_SubTheme_Score': 0.25,
    'Financial_Tightness_SubTheme_Score': 0.33,
    'YieldCurve_SubTheme_Score': 0.33
}

df['Liquidity_Theme_Score'] = sum(
    df[col] * weight for col, weight in weights_liquidity.items()
).round(2)

print(df[['Date', 'Liquidity_Theme_Score']].head())
next

df[['Date',
    'MoneySupply_SubTheme_Score',
    #'Credit_SubTheme_Score',
    'Financial_Tightness_SubTheme_Score',
    'YieldCurve_SubTheme_Score',
    'Liquidity_Theme_Score',
]].to_csv("liquidity_theme_output.csv", index=False)

from google.colab import drive
drive.mount('/content/drive')

"""# Policy Weights"""

import pandas as pd

df = pd.read_csv("policy_zscores_labeled.csv")

# Show column names clearly
for col in df.columns:
    print(f"'{col}'")

df.columns = df.columns.str.strip()

df.rename(columns={
    'Fed Funds Rate (%)': 'FedFunds_Z',
    'Real Fed Funds Rate (%)': 'RealFedFunds_Z',
    'Fed Balance Sheet MoM %': 'BalanceSheet_Z',
    'Federal Budget Deficit (% GDP)': 'FiscalDeficit_Z'
}, inplace=True)

def normalized_contribution(z, weight, cap=2.0):
    z = max(min(z, cap), -cap)
    scaled = (z + cap) / (2 * cap)
    return scaled * weight

df['PolicyRate_SubTheme_Score'] = df['FedFunds_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100
df['RealRate_SubTheme_Score'] = df['RealFedFunds_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100
df['BalanceSheet_SubTheme_Score'] = df['BalanceSheet_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100
df['Fiscal_SubTheme_Score'] = df['FiscalDeficit_Z'].apply(lambda z: normalized_contribution(z, 1.0)) * 100

weights_policy = {
    'PolicyRate_SubTheme_Score': 0.3,
    'RealRate_SubTheme_Score': 0.3,
    'BalanceSheet_SubTheme_Score': 0.2,
    'Fiscal_SubTheme_Score': 0.2
}

df['Policy_Theme_Score'] = sum(
    df[col] * weight for col, weight in weights_policy.items()
).round(2)

print(df[['Date', 'Policy_Theme_Score']].head())

df[['Date',
   'PolicyRate_SubTheme_Score',
    'RealRate_SubTheme_Score',
    'BalanceSheet_SubTheme_Score',
    'Fiscal_SubTheme_Score',
    'Policy_Theme_Score',
]].to_csv("policy_theme_output.csv", index=False)

"""# Labeling"""

import pandas as pd

# Step 1: Read each theme's output file
growth_df = pd.read_csv('growth_theme_output.csv')
inflation_df = pd.read_csv('inflation_theme_output.csv')
policy_df = pd.read_csv('policy_theme_output.csv')
liquidity_df = pd.read_csv('liquidity_theme_output.csv')

# Step 2: Merge them all on 'Date'
merged_df = growth_df.merge(inflation_df, on='Date', how='inner')\
                     .merge(policy_df, on='Date', how='inner')\
                     .merge(liquidity_df, on='Date', how='inner')

# Step 3: Preview the combined macro fingerprint
print(merged_df.head())

def custom_label(score, theme_type):
    if theme_type == 'growth':
        if score >= 85:
            return 'Strong'
        elif score >= 70:
            return 'Moderate'
        elif score >= 50:
            return 'Neutral'
        elif score >= 35:
            return 'Weak'
        else:
            return 'Recessionary'

    elif theme_type == 'inflation':
        if score >= 85:
            return 'High'
        elif score >= 70:
            return 'Rising'
        elif score >= 50:
            return 'Stable'
        elif score >= 35:
            return 'Falling'
        else:
            return 'Low'

    elif theme_type == 'policy':
        if score >= 85:
            return 'Very Tight'
        elif score >= 70:
            return 'Tight'
        elif score >= 50:
            return 'Neutral'
        elif score >= 35:
            return 'Loose'
        else:
            return 'Very Loose'

    elif theme_type == 'liquidity':
        if score >= 85:
            return 'Very Liquid'
        elif score >= 70:
            return 'Liquid'
        elif score >= 50:
            return 'Neutral'
        elif score >= 35:
            return 'Illiquid'
        else:
            return 'Very Illiquid'

merged_df['Growth_Label'] = merged_df['Growth_Theme_Score'].apply(lambda x: custom_label(x, theme_type='growth'))
merged_df['Inflation_Label'] = merged_df['Inflation_Theme_Score'].apply(lambda x: custom_label(x, theme_type='inflation'))
merged_df['Policy_Label'] = merged_df['Policy_Theme_Score'].apply(lambda x: custom_label(x, theme_type='policy'))
merged_df['Liquidity_Label'] = merged_df['Liquidity_Theme_Score'].apply(lambda x: custom_label(x, theme_type='liquidity'))

print(merged_df[['Date',
                 'Growth_Theme_Score', 'Growth_Label',
                 'Inflation_Theme_Score', 'Inflation_Label',
                 'Policy_Theme_Score', 'Policy_Label',
                 'Liquidity_Theme_Score', 'Liquidity_Label']].tail(10))

merged_df.to_csv("macro_fingerprint_summary.csv", index=False)

import matplotlib.pyplot as plt

merged_df.set_index('Date')[[
    'Growth_Theme_Score',
    'Inflation_Theme_Score',
    'Policy_Theme_Score',
    'Liquidity_Theme_Score'
]].plot(figsize=(12, 6), title="Macro Theme Scores Over Time")
plt.axhline(50, color='gray', linestyle='--', alpha=0.5)
plt.show()

# Example: What was happening when all themes were neutral or better?
regime = merged_df[
    (merged_df['Growth_Label'].isin(['Neutral', 'Moderate', 'Strong'])) &
    (merged_df['Inflation_Label'].isin(['Stable', 'Falling', 'Low'])) &
    (merged_df['Policy_Label'].isin(['Neutral', 'Loose', 'Very Loose'])) &
    (merged_df['Liquidity_Label'].isin(['Neutral', 'Liquid', 'Very Liquid']))
]
print(regime.tail(10))